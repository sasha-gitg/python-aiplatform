{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project='sashaproject-1', location='us-central1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.v2.components as comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#             if key in init_arg_names:\n",
    "#                 serialized_args['init'][key] = value\n",
    "#                 #runner_args.append(f'--{INIT_KEY}.{key}={value}')\n",
    "#             elif key in method_arg_names:\n",
    "#                 serialized_args['method'][key] = value\n",
    "#                 runner_args.append(f'--{METHOD_KEY}.{key}={value}')\n",
    "#             elif key == 'staging_bucket':\n",
    "#                 pass\n",
    "                #runner_args.append(f'--staging_bucket={value}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "import inspect\n",
    "import json\n",
    "from kfp.v2 import dsl\n",
    "from kfp import components\n",
    "import kfp\n",
    "import re\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "INIT_KEY = 'init'\n",
    "METHOD_KEY = 'method'\n",
    "\n",
    "gcs_csv_path = 'gs://ucaip-mb-sasha-dev/data/abalone_train.csv'\n",
    "    \n",
    "def method_converter(method, should_serialize_init=False):\n",
    "    method_signature = inspect.signature(method)\n",
    "    method_name = method.__name__\n",
    "    \n",
    "    if inspect.ismethod(method):\n",
    "        cls_name = method.__self__.__name__\n",
    "        init_signature = inspect.signature(method.__self__.__init__)\n",
    "    else:\n",
    "        cls = getattr(inspect.getmodule(method),\n",
    "                      method.__qualname__.split('.<locals>', 1)[0].rsplit('.', 1)[0],\n",
    "                      None)\n",
    "        cls_name = cls.__name__\n",
    "        init_signature = inspect.signature(cls.__init__)\n",
    "    \n",
    "    method_arg_names = set(method_signature.parameters.keys())\n",
    "    init_arg_names = set(init_signature.parameters.keys()) if should_serialize_init else set([])\n",
    "    \n",
    "    \n",
    "    subcommand = [\n",
    "        'python3',\n",
    "        'auto_runner.py',\n",
    "        f'--cls_name={cls_name}',\n",
    "        f'--method_name={method_name}'\n",
    "    ]\n",
    "    \n",
    "    def make_args(sa):\n",
    "        additional_args = []\n",
    "        for key, args in sa.items():\n",
    "            for arg_key, value in args.items():\n",
    "                additional_args.append(f\"    - --{key}.{arg_key}={value}\")\n",
    "        return '\\n'.join(additional_args)\n",
    "\n",
    "    def f(**kwargs):\n",
    "        runner_args = []\n",
    "        inputs = [\"inputs:\"]\n",
    "        input_args = []\n",
    "        input_kwargs = {}\n",
    "        \n",
    "        serialized_args = {\"init\": {}, \"method\": {}}\n",
    "        \n",
    "        for key, value in kwargs.items():\n",
    "            prefix_key = \"init\" if key in init_arg_names else \"method\"\n",
    "            if isinstance(value, kfp.dsl._pipeline_param.PipelineParam):\n",
    "                name = key\n",
    "                inputs.append(\"- {name: %s, type: Artifact}\" % (name))\n",
    "                input_args.append(\"\"\"\n",
    "    - --%s\n",
    "    - {inputUri: %s}\n",
    "\"\"\" % (f'{prefix_key}.{key}', key))\n",
    "                input_kwargs[key] = value\n",
    "            else:\n",
    "                serialized_args[prefix_key][key] = value\n",
    "       \n",
    "        inputs = \"\\n\".join(inputs) if len(inputs) > 1 else ''\n",
    "        input_args = \"\\n\".join(input_args) if input_args else ''\n",
    "        component_text = \"\"\"\n",
    "name: %s-%s\n",
    "%s\n",
    "outputs:\n",
    "- {name: resource_name_output, type: Artifact}\n",
    "implementation:\n",
    "  container:\n",
    "    image: gcr.io/sashaproject-1/mb_sdk_component:latest\n",
    "    command:\n",
    "    - python3\n",
    "    - remote_runner.py\n",
    "    - --cls_name=%s\n",
    "    - --method_name=%s\n",
    "%s\n",
    "    args:\n",
    "    - --resource_name_output_uri\n",
    "    - {outputUri: resource_name_output}\n",
    "%s\n",
    "\"\"\" % (cls_name,\n",
    "       method_name,\n",
    "       inputs,\n",
    "       cls_name,\n",
    "       method_name,\n",
    "       make_args(serialized_args),\n",
    "      input_args)\n",
    "        \n",
    "        print(component_text)\n",
    "        \n",
    "        return components.load_component_from_text(component_text)(**input_kwargs)\n",
    "        #return subprocess.check_output(' '.join(subcommand + runner_args), shell=True)\n",
    "\n",
    "    return f\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from kfp import dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import dsl\n",
    "from kfp.v2 import compiler\n",
    "\n",
    "\n",
    "\n",
    "@kfp.v2.dsl.pipeline(name='datasetcreatetest')\n",
    "def pipeline():\n",
    "    op = DatasetCreateOp(\n",
    "      project='sashaproject-1',\n",
    "      display_name='abalone',\n",
    "      metadata_schema_uri=aiplatform.schema.dataset.metadata.tabular,\n",
    "      gcs_source=gcs_csv_path)\n",
    "    print(op)\n",
    "    \n",
    "compiler.Compiler().compile(pipeline_func=pipeline,\n",
    "                            pipeline_root='gs://ucaip-mb-sasha-dev/pipeline-dev',\n",
    "                            output_path='pipeline.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.pipelines.Datacr\n",
    "\n",
    "DatasetCreateOp = method_converter(aiplatform.Dataset.create)\n",
    "\n",
    "CustomContainerTrainingJobRunOp = method_converter(aiplatform.CustomContainerTrainingJob.run,\n",
    "                                                  should_serialize_init=True)\n",
    "\n",
    "ModelDeployOp = method_converter(aiplatform.Model.deploy, should_serialize_init=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.pipeline(name='customtrainingtest')\n",
    "def pipeline():\n",
    "    dataset_create_op = DatasetCreateOp(\n",
    "      project='sashaproject-1',\n",
    "      display_name='bq_iris_dataset',\n",
    "      bq_source=f'bq://sashaproject-1.ml_datasets.iris',\n",
    "      metadata_schema_uri=aiplatform.schema.dataset.metadata.tabular)\n",
    "    \n",
    "    custom_training_op = CustomContainerTrainingJobRunOp(\n",
    "        project='sashaproject-1',\n",
    "        container_uri='gcr.io/sashaproject-1/test-custom-container:latest',\n",
    "        model_serving_container_image_uri='gcr.io/cloud-aiplatform/prediction/tf2-cpu.2-2:latest',\n",
    "        dataset=dataset_create_op.outputs['resource_name_output'],\n",
    "        #dataset='projects/40556267596/locations/us-central1/datasets/1832349321828237312',\n",
    "        replica_count=1, \n",
    "        model_display_name='bq-iris-model',\n",
    "        bigquery_destination=f'bq://sashaproject-1',\n",
    "        display_name='my-training-job',\n",
    "        staging_bucket='gs://ucaip-mb-sasha-dev',\n",
    "    )\n",
    "    \n",
    "    model_deploy_op = ModelDeployOp(\n",
    "        project='sashaproject-1',\n",
    "        model_name=custom_training_op.outputs['resource_name_output'],\n",
    "        machine_type='n1-standard-4')\n",
    "    \n",
    "compiler.Compiler().compile(pipeline_func=pipeline,\n",
    "                        pipeline_root='gs://ucaip-mb-sasha-dev/pipeline-dev',\n",
    "                        output_path='pipeline.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat pipeline.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiplatform.pipelines import client\n",
    "\n",
    "api_client = client.Client(project_id='sashaproject-1', region='us-central1',\n",
    "                           api_key='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_client.create_run_from_job_spec('pipeline.json', pipeline_root='gs://ucaip-mb-sasha-dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_client.get_job('customtrainingtest-20210317152513')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-triangle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
